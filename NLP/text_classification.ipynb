{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "wSsL3g6KGRoX"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchtext.datasets import IMDB\n",
        "from torchtext.vocab import build_vocab_from_iterator, Vocab\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdata"
      ],
      "metadata": {
        "id": "2B1FjoLNUf6w"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Preprocessing"
      ],
      "metadata": {
        "id": "pFI-lsGfqWju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = IMDB(split='train')\n",
        "test_data = IMDB(split='test')"
      ],
      "metadata": {
        "id": "vqZpe91oGpAc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data, valid_data = random_split(list(training_data),[20000,5000])\n",
        "test_data, _ = random_split(list(test_data),[25000,0])"
      ],
      "metadata": {
        "id": "Ng-XarJGpIAH"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(training_data))\n",
        "print(type(valid_data))\n",
        "print(type(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ActaIcg1gm1X",
        "outputId": "9920e3e8-4afe-48dd-8a70-095a4ea07bb6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.utils.data.dataset.Subset'>\n",
            "<class 'torch.utils.data.dataset.Subset'>\n",
            "<class 'torch.utils.data.dataset.Subset'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IterDataPipe = iter(training_data)\n",
        "def get_tokenizer(sentence):\n",
        "  tokenized = re.sub(r'[^\\w\\s]+',' ',sentence.lower())\n",
        "  return tokenized.split()"
      ],
      "metadata": {
        "id": "GBhZfaTmRDGl"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yield_tokens(example):\n",
        "  for label,text in example:\n",
        "    yield get_tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(IterDataPipe))\n",
        "vocab.insert_token(\"<pad>\",0)\n",
        "vocab.insert_token(\"<unk>\",1)\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "metadata": {
        "id": "tRexTM-dPhlR"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textpipeline = lambda x: vocab(get_tokenizer(x))\n",
        "labelpipeline = lambda x:1 if x == 'pos' else 0"
      ],
      "metadata": {
        "id": "1Q_R1YQBw9_E"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(data_iter):\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  text_processed, label_processed, length = [],[],[]\n",
        "\n",
        "  for y_batch,x_batch in data_iter:\n",
        "    text = torch.tensor(textpipeline(x_batch),dtype=torch.float32)\n",
        "    text_processed.append(text)\n",
        "    length.append(text.size(0))\n",
        "    label = torch.tensor(labelpipeline(y_batch),dtype=torch.float32)\n",
        "    label_processed.append(label)\n",
        "    \n",
        "  padded_text = pad_sequence(text_processed,batch_first=True).clone().detach().requires_grad_(True)\n",
        "  label_processed = torch.tensor(label_processed)\n",
        "  length = torch.tensor(length,dtype=torch.float32)\n",
        "  return padded_text.to(device),label_processed.to(device), length"
      ],
      "metadata": {
        "id": "u_7qN0wh0Eeq"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## sanity check\n",
        "batch = [('neg','This is bad'),('pos','This is good'),('pos','This is good again')]\n",
        "print(collate_batch(batch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjESvzE1s1us",
        "outputId": "3121deec-e91f-45c2-e6e9-357ae111f6b8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[ 12.,   7.,  77.,   0.],\n",
            "        [ 12.,   7.,  51.,   0.],\n",
            "        [ 12.,   7.,  51., 177.]], device='cuda:0', grad_fn=<ToCopyBackward0>), tensor([0., 1., 1.], device='cuda:0'), tensor([3., 3., 4.]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(training_data,batch_size=32,collate_fn=collate_batch,shuffle=True,drop_last=True)\n",
        "valid_dl = DataLoader(valid_data,batch_size=32,collate_fn=collate_batch,drop_last=True)\n",
        "test_dl = DataLoader(test_data,batch_size=32,collate_fn=collate_batch,drop_last=True)"
      ],
      "metadata": {
        "id": "6sbNcf9l5gmg"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition\n"
      ],
      "metadata": {
        "id": "z9hp9Lt5qdj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "embed_size = 20\n",
        "rnn_hidden_size = 64\n",
        "fc_hidden_size = 64"
      ],
      "metadata": {
        "id": "GYzQYkLprJbW"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassification(nn.Module):\n",
        "  def __init__(self,vocab_size:int, embed_size:int,rnn_hidden_size:int,fc_hidden_size:int):\n",
        "    super(TextClassification,self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size,embed_size,padding_idx=0)\n",
        "    self.lstm = nn.LSTM(embed_size,rnn_hidden_size,batch_first=True)\n",
        "    self.linear_1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear_2 = nn.Linear(fc_hidden_size,1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self,input,length):\n",
        "    ## lstm hidden and cell states default to zero\n",
        "    input = input.to(torch.int64)     ## due to argument type mismatch\n",
        "    out = self.embedding(input)\n",
        "    out = nn.utils.rnn.pack_padded_sequence(out,length.cpu().numpy(),batch_first=True, enforce_sorted=False)  ##length should 1D cpu tensor\n",
        "    out, (hidden,cell) = self.lstm(out)\n",
        "    out = hidden[-1,:,:]\n",
        "    out = self.linear_1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear_2(out)\n",
        "    out = self.sigmoid(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "cCtxGPLOqRkn"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TextClassification(vocab_size,embed_size,rnn_hidden_size,fc_hidden_size)\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEMjN_UUdzyX",
        "outputId": "595e52d0-c3a8-4dc8-a579-f0c4ebab393e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextClassification(\n",
              "  (embedding): Embedding(68516, 20, padding_idx=0)\n",
              "  (lstm): LSTM(20, 64, batch_first=True)\n",
              "  (linear_1): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (linear_2): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training and Evaluation"
      ],
      "metadata": {
        "id": "5MAtNfJxzT9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "-quRVeAAhZLP"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader):\n",
        "  model.train()\n",
        "  total_loss, total_accuracy = 0.0, 0.0\n",
        "  for x_batch,y_batch, length in dataloader:\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(x_batch,length)[:,0]   ## due to target size mismatch \n",
        "    loss = loss_fn(pred,y_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_accuracy += ((pred >= 0.5) == y_batch).float().sum().item()\n",
        "    total_loss += loss.item()*y_batch.size(0)\n",
        "  train_loss = total_loss/len(dataloader.dataset)\n",
        "  train_accuracy = total_accuracy/len(dataloader.dataset)\n",
        "  return train_loss, train_accuracy\n",
        "  \n",
        "\n",
        "def evaluate(dataloader):\n",
        "  model.eval()\n",
        "  total_loss, total_accuracy = 0.0, 0.0\n",
        "  with torch.no_grad():\n",
        "    for x_batch, y_batch, length in dataloader:\n",
        "      pred = model(x_batch,length)[:,0]    ##due to target size mismatch\n",
        "      loss = loss_fn(pred,y_batch)\n",
        "      total_accuracy += ((pred >= 0.5).float() == y_batch).float().sum().item()\n",
        "      total_loss += loss.item()*y_batch.size(0)\n",
        "  valid_loss = total_loss/len(dataloader.dataset)\n",
        "  valid_accuracy = total_accuracy/len(dataloader.dataset)\n",
        "  return valid_loss, valid_accuracy"
      ],
      "metadata": {
        "id": "OG6TeSbaeMeP"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "torch.manual_seed(1)\n",
        "for epoch in range(num_epochs):\n",
        "  train_loss, train_accuracy = train(train_dl)\n",
        "  valid_loss, valid_accuracy = evaluate(valid_dl)\n",
        "  print(f\"Epoch: {epoch}, Train accuracy: {train_accuracy:.4f}, Valid accuracy: {valid_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svEnbweFumDF",
        "outputId": "c9cebc89-dd72-4999-aae8-fb75e8be2c22"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Train accuracy: 0.6170, Valid accuracy: 0.6516\n",
            "Epoch: 1, Train accuracy: 0.7409, Valid accuracy: 0.7538\n",
            "Epoch: 2, Train accuracy: 0.7683, Valid accuracy: 0.7280\n",
            "Epoch: 3, Train accuracy: 0.8097, Valid accuracy: 0.8246\n",
            "Epoch: 4, Train accuracy: 0.8802, Valid accuracy: 0.8452\n",
            "Epoch: 5, Train accuracy: 0.9060, Valid accuracy: 0.8560\n",
            "Epoch: 6, Train accuracy: 0.9307, Valid accuracy: 0.8604\n",
            "Epoch: 7, Train accuracy: 0.9472, Valid accuracy: 0.8624\n",
            "Epoch: 8, Train accuracy: 0.9598, Valid accuracy: 0.8698\n",
            "Epoch: 9, Train accuracy: 0.9721, Valid accuracy: 0.8700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = evaluate(test_dl)\n",
        "print(f\"Test Accuracy: {test_accuracy: .4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WidSZJPBfQGf",
        "outputId": "89593945-d75b-4730-d167-33e9f5951873"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  0.8548\n"
          ]
        }
      ]
    }
  ]
}