{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_language_model .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sindhu213/Pytorch/blob/main/NLP/rnn_language_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LcpNlmMyBiu4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b697aea2-56a5-4c87-878a-2e00a342782b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\",force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/My\\ Drive/assets"
      ],
      "metadata": {
        "id": "znMkO2ldHRLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1af8f954-789d-4ca2-c06c-8c217ec49a2f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from torch import nn, Tensor\n",
        "from typing import List,Tuple\n",
        "from torchtext.vocab import vocab\n",
        "from collections import Counter,OrderedDict\n",
        "from torch.utils.data import DataLoader,Dataset"
      ],
      "metadata": {
        "id": "il59hVX1CbVb"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Preprocessing"
      ],
      "metadata": {
        "id": "XltwOBFCJJbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_dir = Path('./AndThenThereWereNone.txt')\n",
        "with open(file_dir, 'r') as file:\n",
        "  text = file.read()"
      ],
      "metadata": {
        "id": "17g7fFrNCzWP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tokenizer(sentence):\n",
        "  tokenized = re.sub(r'[^\\w\\s]+',' ',sentence.lower())\n",
        "  return tokenized.split()"
      ],
      "metadata": {
        "id": "fNb7KpSDKuu7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter = Counter(get_tokenizer(text))\n",
        "sorted_by_freq = sorted(counter.items(),key=lambda x: x[1], reverse=True)\n",
        "ordered_dict = OrderedDict(sorted_by_freq)\n",
        "\n",
        "Vocab = vocab(ordered_dict,min_freq=2,specials=[\"<unk>\"])    \n",
        "Vocab.set_default_index(0)"
      ],
      "metadata": {
        "id": "WNaS6QaYef6o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def onehotvector(list_of_ints):\n",
        "  overall_list = np.zeros((len(list_of_ints),len(Vocab)))   \n",
        "  for index, value in enumerate(list_of_ints):\n",
        "    overall_list[index,value] = 1\n",
        "  return overall_list"
      ],
      "metadata": {
        "id": "td8O-ZOMv-vX"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = lambda x: Vocab(get_tokenizer(x))  "
      ],
      "metadata": {
        "id": "lFWsUZlKIgd4"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset:\n",
        "\n",
        "  def __init__(self,input:List[str],seq_length:int):    \n",
        "    self.input = input\n",
        "    self.sl = seq_length\n",
        "\n",
        "  def collate(self) -> Tuple[Tensor,Tensor]:\n",
        "    container = []\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    for i in range(0,len(self.input)-self.sl,self.sl):\n",
        "        data = torch.tensor(onehotvector(self.input[i:i+self.sl]), dtype=torch.float32, device=device)   \n",
        "        label = torch.tensor(onehotvector(self.input[i+1:i+self.sl+1]), dtype=torch.float32, device=device)    \n",
        "        container.append((data,label))\n",
        "\n",
        "    return container"
      ],
      "metadata": {
        "id": "s0srHBibIlzH"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = text_pipeline(text)"
      ],
      "metadata": {
        "id": "YDb0dq7eXXlK"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 60       ## small seq_length due to long term dependency problem, might change \n",
        "batch_size = 32\n",
        "\n",
        "torch.manual_seed(42)\n",
        "input_dataset = TextDataset(input_data,seq_length).collate()\n",
        "dataloader = DataLoader(input_dataset,batch_size=batch_size,drop_last=True,shuffle=True)  "
      ],
      "metadata": {
        "id": "vcHphD2k6bFd"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(iter(dataloader))\n",
        "print(x_batch.shape,y_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFBCGneR0qGq",
        "outputId": "77c6ca21-b92a-4b5c-82d1-8c18dbd48bd3"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 60, 2618]) torch.Size([32, 60, 2618])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition"
      ],
      "metadata": {
        "id": "rmwUqha5oAdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(Vocab)\n",
        "embed_dim = 128\n",
        "rnn_hidden_size = 64"
      ],
      "metadata": {
        "id": "hBJ0xK4m6QvC"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModelling(nn.Module):\n",
        "\n",
        "  def __init__(self,vocab_size,embed_dim,rnn_hidden_dim):\n",
        "    super(LanguageModelling,self).__init__()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.rnn_hidden_size = rnn_hidden_dim\n",
        "    self.embedding = nn.Embedding(vocab_size, embed_dim)  \n",
        "    self.lstm = nn.LSTM(embed_dim,rnn_hidden_size,batch_first=True)   \n",
        "    self.fc = nn.Linear(rnn_hidden_size,vocab_size)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self,input,hidden,cell):\n",
        "    input = input.to(torch.int64) \n",
        "    out = self.embedding(input)\n",
        "    out,(hidden,cell) = self.lstm(out,(hidden,cell))      \n",
        "    out = self.fc(out).reshape(self.vocab_size,-1) \n",
        "    out = self.softmax(out) \n",
        "    return out,hidden,cell\n",
        "\n",
        "  def init_hidden_and_cell(self,batch_size):\n",
        "    hidden = torch.zeros(1,batch_size,self.rnn_hidden_size)\n",
        "    cell = torch.zeros(1,batch_size,self.rnn_hidden_size)\n",
        "    return hidden, cell"
      ],
      "metadata": {
        "id": "gUXheAQVo0nA"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden,cell = model.init_hidden_and_cell(32)\n",
        "xbatch,ynatch = next(iter(dataloader))\n",
        "out, hidden, cell = model(xbatch[:,0],hidden,cell)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWUVbej11QDH",
        "outputId": "234f5fe3-6fa8-4b1d-9e0d-bb4143916e46"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 6853924])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training and Evaluation"
      ],
      "metadata": {
        "id": "CX6yeHEtZ6LH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModelling(vocab_size,embed_dim,rnn_hidden_size)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIT6ZdFMa1rl",
        "outputId": "246e88ae-7caf-4da3-e302-b4fdf5d870f6"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModelling(\n",
              "  (embedding): Embedding(2618, 128)\n",
              "  (lstm): LSTM(128, 64, batch_first=True)\n",
              "  (fc): Linear(in_features=64, out_features=2618, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001) "
      ],
      "metadata": {
        "id": "sfyo6FGhZuq8"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "def train(data_iter):\n",
        "  for epoch in range(num_epochs):\n",
        "    hidden,cell = model.init_hidden_and_cell(batch_size)\n",
        "    x_batch, y_batch = next(iter(data_iter))\n",
        "    optimizer.zero_grad()\n",
        "    loss = 0.0\n",
        "    for c in range(seq_length):\n",
        "      out,hidden,cell = model(x_batch[:,c],hidden,cell)\n",
        "      loss += loss_fn(y_batch[:,c],out)     ##y_batch not of right shape\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss = loss.item()/seq_length\n",
        "    if epoch % 10 == 0:\n",
        "      print(f'Epoch {epoch} loss: {loss:.4f}')"
      ],
      "metadata": {
        "id": "zQPEifit2vII"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(dataloader)"
      ],
      "metadata": {
        "id": "_ruS28bAq_dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seeded_text,max_length):\n",
        "  pass"
      ],
      "metadata": {
        "id": "dMhSqL-tY7J0"
      },
      "execution_count": 51,
      "outputs": []
    }
  ]
}