{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_language_model .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sindhu213/Pytorch/blob/main/NLP/rnn_language_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LcpNlmMyBiu4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "777f5c12-ef91-4359-bca8-62a602835ec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\",force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/My\\ Drive/assets"
      ],
      "metadata": {
        "id": "znMkO2ldHRLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16d7a825-4bd5-4516-dead-71f735683e26"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch import nn, Tensor\n",
        "from typing import List,Tuple\n",
        "from torchtext.vocab import vocab\n",
        "from collections import Counter,OrderedDict\n",
        "from torch.utils.data import DataLoader,Dataset"
      ],
      "metadata": {
        "id": "il59hVX1CbVb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Preprocessing"
      ],
      "metadata": {
        "id": "XltwOBFCJJbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_dir = Path('./AndThenThereWereNone.txt')\n",
        "with open(file_dir, 'r') as file:\n",
        "  text = file.read()"
      ],
      "metadata": {
        "id": "17g7fFrNCzWP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tokenizer(sentence):\n",
        "  tokenized = re.sub(r'[^\\w\\s]+',' ',sentence.lower())\n",
        "  return tokenized.split()"
      ],
      "metadata": {
        "id": "fNb7KpSDKuu7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter = Counter(get_tokenizer(text))\n",
        "sorted_by_freq = sorted(counter.items(),key=lambda x: x[1], reverse=True)\n",
        "ordered_dict = OrderedDict(sorted_by_freq)\n",
        "\n",
        "Vocab = vocab(ordered_dict,min_freq=2,specials=[\"<unk>\"])    \n",
        "Vocab.set_default_index(0)"
      ],
      "metadata": {
        "id": "WNaS6QaYef6o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = lambda x: Vocab(get_tokenizer(x))  "
      ],
      "metadata": {
        "id": "lFWsUZlKIgd4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset:\n",
        "\n",
        "  def __init__(self,input:List[str],seq_length:int):    \n",
        "    self.input = input\n",
        "    self.sl = seq_length\n",
        "\n",
        "  def collate(self) -> Tuple[Tensor,Tensor]:\n",
        "    container = []\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    for i in range(0,len(self.input)-self.sl,self.sl):\n",
        "        data = torch.tensor(self.input[i:i+self.sl], dtype=torch.float32, device=device)   \n",
        "        label = torch.tensor(self.input[i+1:i+self.sl+1], dtype=torch.float32, device=device)    \n",
        "        container.append((data,label))\n",
        "\n",
        "    return container"
      ],
      "metadata": {
        "id": "s0srHBibIlzH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = text_pipeline(text)"
      ],
      "metadata": {
        "id": "YDb0dq7eXXlK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## sanity check\n",
        "\n",
        "torch.manual_seed(42)\n",
        "input_dataset = TextDataset(input_data,seq_length =4).collate()\n",
        "test_dataloader = DataLoader(input_dataset, batch_size=3,shuffle=True,drop_last=False)\n",
        "\n",
        "for input,label in test_dataloader:\n",
        "  print(\"Input: \",input)\n",
        "  print(\"Label: \",label)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GUoF_-JNECm",
        "outputId": "5014a406-b437-4378-c17e-911e9f112d80"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  tensor([[  12.,   16., 1892.,   58.],\n",
            "        [  23.,   76.,   19.,   46.],\n",
            "        [  11.,  153.,   34.,   64.]])\n",
            "Label:  tensor([[  16., 1892.,   58.,   12.],\n",
            "        [  76.,   19.,   46.,  444.],\n",
            "        [ 153.,   34.,   64.,  529.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 60       ## small seq_length due to long term dependency problem, might change \n",
        "batch_size = 32\n",
        "\n",
        "torch.manual_seed(42)\n",
        "input_dataset = TextDataset(input_data,seq_length).collate()\n",
        "dataloader = DataLoader(input_dataset,batch_size=batch_size,drop_last=True,shuffle=True)  "
      ],
      "metadata": {
        "id": "vcHphD2k6bFd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition"
      ],
      "metadata": {
        "id": "rmwUqha5oAdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(Vocab)\n",
        "embed_dim = 128\n",
        "rnn_hidden_size = 64"
      ],
      "metadata": {
        "id": "hBJ0xK4m6QvC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModelling(nn.Module):\n",
        "\n",
        "  def __init__(self,vocab_size,embed_dim,rnn_hidden_dim):\n",
        "    super(LanguageModelling,self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embed_dim)  \n",
        "    self.lstm_layer1 = nn.LSTM(embed_dim,rnn_hidden_size,batch_first=True)   \n",
        "    self.lstm_layer2 = nn.LSTM(rnn_hidden_dim,vocab_size,batch_first=True)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self,input,hidden_1,cell_1,hidden_2,cell_2):\n",
        "    input = input.to(torch.int64) \n",
        "    out = self.embedding(input)\n",
        "    out,(_,_) = self.lstm_layer1(out,(hidden_1,cell_1))\n",
        "    out,(_,_) = self.lstm_layer2(out,(hidden_2,cell_2))    ## might output of hidden and cell states if needed\n",
        "    out = self.softmax(out) \n",
        "    return out\n",
        "\n",
        "  @staticmethod\n",
        "  def init_hidden_and_cell(batch_size,rnn_hidden_size):\n",
        "    hidden = torch.zeros(1,batch_size,rnn_hidden_size)\n",
        "    cell = torch.zeros(1,batch_size,rnn_hidden_size)\n",
        "    return hidden,cell"
      ],
      "metadata": {
        "id": "gUXheAQVo0nA"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training and Evaluation"
      ],
      "metadata": {
        "id": "CX6yeHEtZ6LH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModelling(vocab_size,embed_dim,rnn_hidden_size)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIT6ZdFMa1rl",
        "outputId": "b4c809c2-9ae7-4702-e4e9-d92c5b0dc125"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModelling(\n",
              "  (embedding): Embedding(2618, 128)\n",
              "  (lstm_layer1): LSTM(128, 64, batch_first=True)\n",
              "  (lstm_layer2): LSTM(64, 2618, batch_first=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001) "
      ],
      "metadata": {
        "id": "sfyo6FGhZuq8"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "def train(data_iter):\n",
        "  for epoch in range(num_epochs):\n",
        "    x_batch, y_batch = next(iter(data_iter))\n",
        "    hidden, cell = model.init_hidden_and_cell(batch_size)\n",
        "    optimizer.zero_grad()\n",
        "    loss = 0.0\n",
        "    for c in range(seq_length):\n",
        "      out, hidden, cell = model(x_batch[:,c],hidden,cell)\n",
        "      loss += loss_fn(y_batch[:,c],out)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss = loss.item()/seq_length\n",
        "    if epoch % 10 == 0:\n",
        "      print(f'Epoch {epoch} loss: {loss:.4f}')"
      ],
      "metadata": {
        "id": "zQPEifit2vII"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "-xWkXxwn6YzF",
        "outputId": "33f55ced-0cb8-4d67-8932-04d9fc647d2e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-786b1a7126fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-61-072a1c702cdc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_iter)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden_and_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: init_hidden_and_cell() missing 1 required positional argument: 'rnn_hidden_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seeded_text,max_length):\n",
        "  pass"
      ],
      "metadata": {
        "id": "dMhSqL-tY7J0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}