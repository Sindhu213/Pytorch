{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_language_model .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sindhu213/Pytorch/blob/main/NLP/rnn_language_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LcpNlmMyBiu4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9026dd42-4fa2-4a88-b6c2-ef64a9dba863"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\",force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/My\\ Drive/assets"
      ],
      "metadata": {
        "id": "znMkO2ldHRLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87e441e0-16e6-410a-8aee-15c7cb70cbd4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from torch import nn, Tensor\n",
        "from typing import List,Tuple\n",
        "from torchtext.vocab import vocab\n",
        "from collections import Counter,OrderedDict\n",
        "from torch.utils.data import DataLoader,Dataset"
      ],
      "metadata": {
        "id": "il59hVX1CbVb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Preprocessing"
      ],
      "metadata": {
        "id": "XltwOBFCJJbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_dir = Path('./AndThenThereWereNone.txt')\n",
        "with open(file_dir, 'r') as file:\n",
        "  text = file.read()"
      ],
      "metadata": {
        "id": "17g7fFrNCzWP"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tokenizer(sentence):\n",
        "  tokenized = re.sub(r'[^\\w\\s]+',' ',sentence.lower())\n",
        "  return tokenized.split()"
      ],
      "metadata": {
        "id": "fNb7KpSDKuu7"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter = Counter(get_tokenizer(text))\n",
        "sorted_by_freq = sorted(counter.items(),key=lambda x: x[1], reverse=True)\n",
        "ordered_dict = OrderedDict(sorted_by_freq)\n",
        "\n",
        "Vocab = vocab(ordered_dict,min_freq=2)    \n",
        "Vocab.set_default_index(0)"
      ],
      "metadata": {
        "id": "WNaS6QaYef6o"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = lambda x: Vocab(get_tokenizer(x))  "
      ],
      "metadata": {
        "id": "lFWsUZlKIgd4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset:\n",
        "\n",
        "  def __init__(self,input:List[str],seq_length:int):    \n",
        "    self.input = input\n",
        "    self.sl = seq_length\n",
        "\n",
        "  def collate(self) -> Tuple[Tensor,Tensor]:\n",
        "    container = []\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    for i in range(0,len(self.input)-self.sl,self.sl):\n",
        "        data = torch.tensor(self.input[i:i+self.sl], device=device)   \n",
        "        label = torch.tensor(self.input[i+1:i+self.sl+1], device=device)    \n",
        "        container.append((data,label))\n",
        "\n",
        "    return container"
      ],
      "metadata": {
        "id": "s0srHBibIlzH"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = text_pipeline(text)"
      ],
      "metadata": {
        "id": "YDb0dq7eXXlK"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100       \n",
        "batch_size = 32\n",
        "\n",
        "torch.manual_seed(42)\n",
        "input_dataset = TextDataset(input_data,seq_length).collate()\n",
        "dataloader = DataLoader(input_dataset,batch_size=batch_size,drop_last=True,shuffle=True)  "
      ],
      "metadata": {
        "id": "vcHphD2k6bFd"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition"
      ],
      "metadata": {
        "id": "rmwUqha5oAdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(Vocab)\n",
        "embed_dim = 128\n",
        "rnn_hidden_size = 64"
      ],
      "metadata": {
        "id": "hBJ0xK4m6QvC"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModelling(nn.Module):\n",
        "\n",
        "  def __init__(self,vocab_size,embed_dim,rnn_hidden_dim):\n",
        "    super(LanguageModelling,self).__init__()\n",
        "    self.rnn_hidden_size = rnn_hidden_dim\n",
        "    self.embedding = nn.Embedding(vocab_size, embed_dim)  \n",
        "    self.lstm = nn.LSTM(embed_dim,rnn_hidden_size,batch_first=True)   \n",
        "    self.fc = nn.Linear(rnn_hidden_size,vocab_size)\n",
        "\n",
        "  def forward(self,input,hidden):\n",
        "    \"\"\"\n",
        "    INPUT:\n",
        "        input: [batch_size,seq_length]\n",
        "        hidden: [1,batch_size,rnn_hidden_size]\n",
        "\n",
        "    RETURNS:\n",
        "        out: [batch_size,seq_length,vocab_size]\n",
        "        hidden: [1,batch_size,rnn_hidden_size]\n",
        "    \"\"\"\n",
        "    out = self.embedding(input)   \n",
        "    out,hidden = self.lstm(out,hidden)   \n",
        "    out = self.fc(out)  \n",
        "    return out, hidden\n",
        "\n",
        "  def init_hidden(self,batch_size):\n",
        "    hidden = torch.zeros(1,batch_size,self.rnn_hidden_size)    \n",
        "    cell = torch.zeros(1,batch_size,self.rnn_hidden_size)\n",
        "    return hidden, cell\n",
        "\n",
        "  def detach_hidden(self, hidden):\n",
        "    hidden, cell = hidden\n",
        "    hidden = hidden.detach()\n",
        "    cell = cell.detach()\n",
        "    return hidden, cell"
      ],
      "metadata": {
        "id": "gUXheAQVo0nA"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training and Evaluation"
      ],
      "metadata": {
        "id": "CX6yeHEtZ6LH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = LanguageModelling(vocab_size,embed_dim,rnn_hidden_size)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIT6ZdFMa1rl",
        "outputId": "8dae9136-d357-4713-899d-38a99c5a3f52"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModelling(\n",
              "  (embedding): Embedding(2617, 128)\n",
              "  (lstm): LSTM(128, 64, batch_first=True)\n",
              "  (fc): Linear(in_features=64, out_features=2617, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.005) "
      ],
      "metadata": {
        "id": "sfyo6FGhZuq8"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x_batch: [batch_size,seq_length]\n",
        "# y_batch: [batch_size,seq_length]\n",
        "\n",
        "def train(data_iter):\n",
        "  epoch_loss =  0.0\n",
        "  model.train()\n",
        "  hidden = model.init_hidden(batch_size)\n",
        "  for x_batch,y_batch in dataloader:   \n",
        "    optimizer.zero_grad()\n",
        "    hidden = model.detach_hidden(hidden)\n",
        "    prediction, hidden = model(x_batch,hidden)\n",
        "    prediction = prediction.reshape(batch_size*seq_length,vocab_size)\n",
        "    y_batch = y_batch.reshape(-1)\n",
        "    loss = loss_fn(prediction,y_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()*seq_length\n",
        "      \n",
        "  return epoch_loss/seq_length"
      ],
      "metadata": {
        "id": "nqy2SSuWjTsl"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "  training_loss = train(dataloader)\n",
        "  print(f\"Epoch: {epoch}, Training loss: {training_loss: .4f}\")"
      ],
      "metadata": {
        "id": "7PkiXLDVJDRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfce4dba-3a78-4c95-96b1-abba152c427a"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Training loss:  82.2165\n",
            "Epoch: 1, Training loss:  79.9211\n",
            "Epoch: 2, Training loss:  78.4385\n",
            "Epoch: 3, Training loss:  77.1364\n",
            "Epoch: 4, Training loss:  75.9658\n",
            "Epoch: 5, Training loss:  74.8989\n",
            "Epoch: 6, Training loss:  73.9450\n",
            "Epoch: 7, Training loss:  72.9598\n",
            "Epoch: 8, Training loss:  72.0118\n",
            "Epoch: 9, Training loss:  71.1567\n",
            "Epoch: 10, Training loss:  70.2972\n",
            "Epoch: 11, Training loss:  69.4304\n",
            "Epoch: 12, Training loss:  68.6970\n",
            "Epoch: 13, Training loss:  67.9010\n",
            "Epoch: 14, Training loss:  67.0986\n",
            "Epoch: 15, Training loss:  66.3437\n",
            "Epoch: 16, Training loss:  65.6501\n",
            "Epoch: 17, Training loss:  64.9205\n",
            "Epoch: 18, Training loss:  64.2406\n",
            "Epoch: 19, Training loss:  63.5496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "def generate_text(seeded_text,text_len=10):\n",
        "    model.eval()\n",
        "    tokens = text_pipeline(seeded_text)\n",
        "    batch_size = 1\n",
        "    hidden = model.init_hidden(batch_size)\n",
        "    with torch.no_grad():\n",
        "        for i in range(text_len):\n",
        "            input = torch.LongTensor([tokens])\n",
        "            prediction, hidden = model(input, hidden)\n",
        "            probs = torch.softmax(prediction[:, -1], dim=-1) \n",
        "            prediction = torch.multinomial(probs, num_samples=1).item()\n",
        "            tokens.append(prediction)\n",
        "\n",
        "    itos = Vocab.get_itos()\n",
        "    tokens = [itos[i] for i in tokens]\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "V8O1iFQhn65x"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\"The man\",10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3ux-CBJnhZC",
        "outputId": "a98bf882-dcf0-4ce6-8b43-8a47e28e12aa"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'man',\n",
              " 'who',\n",
              " 'now',\n",
              " 'just',\n",
              " 'there',\n",
              " 'were',\n",
              " 'no',\n",
              " 'one',\n",
              " 'of',\n",
              " 'them',\n",
              " 'er']"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    }
  ]
}