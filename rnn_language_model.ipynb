{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_language_model .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sindhu213/Pytorch/blob/main/rnn_language_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LcpNlmMyBiu4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a0e3426-f348-4a96-888d-7db745eac297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/My\\ Drive/resources"
      ],
      "metadata": {
        "id": "znMkO2ldHRLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9babcfe-24a6-4f5b-ff36-0192346c27da"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/resources\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch import nn, Tensor\n",
        "from typing import List,Tuple\n",
        "from torchtext.vocab import vocab\n",
        "from collections import Counter,OrderedDict\n",
        "from torch.utils.data import DataLoader,Dataset"
      ],
      "metadata": {
        "id": "il59hVX1CbVb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Preprocessing"
      ],
      "metadata": {
        "id": "XltwOBFCJJbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_dir = Path('./AndThenThereWereNone.txt')\n",
        "with open(file_dir, 'r') as file:\n",
        "  text = file.read()"
      ],
      "metadata": {
        "id": "17g7fFrNCzWP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tokenizer(sentence):\n",
        "  tokenized = re.sub(r'[^\\w\\s]+',' ',sentence.lower())\n",
        "  return tokenized.split()"
      ],
      "metadata": {
        "id": "fNb7KpSDKuu7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter = Counter(get_tokenizer(text))\n",
        "sorted_by_freq = sorted(counter.items(),key=lambda x: x[1], reverse=True)\n",
        "ordered_dict = OrderedDict(sorted_by_freq)\n",
        "\n",
        "Vocab = vocab(ordered_dict,min_freq=2,specials=[\"<unk>\"])     ## might add <eos>\n",
        "Vocab.set_default_index(0)"
      ],
      "metadata": {
        "id": "WNaS6QaYef6o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = lambda x: Vocab(get_tokenizer(x))  "
      ],
      "metadata": {
        "id": "lFWsUZlKIgd4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset:\n",
        "\n",
        "  def __init__(self,input:List[str],chunk_size:int):    \n",
        "    self.input = input\n",
        "    self.b_S = chunk_size\n",
        "\n",
        "  def collate(self) -> Tuple[Tensor,Tensor]:\n",
        "    container = []\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    for i in range(0,len(self.input)-self.b_S,self.b_S):\n",
        "        data = torch.tensor(self.input[i:i+self.b_S],dtype=torch.float32,device=device)\n",
        "        label = torch.tensor(self.input[i+1:i+self.b_S+1],dtype=torch.float32,device=device)\n",
        "        container.append((data,label))\n",
        "\n",
        "    return container"
      ],
      "metadata": {
        "id": "s0srHBibIlzH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = text_pipeline(text)\n",
        "chunk_size = 5\n",
        "batch_size = 3\n",
        "\n",
        "torch.manual_seed(42)\n",
        "input_dataset = TextDataset(input_data,chunk_size).collate()\n",
        "dataloader = DataLoader(input_dataset,batch_size=batch_size,drop_last=True,shuffle=True)  "
      ],
      "metadata": {
        "id": "vcHphD2k6bFd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## sanity check\n",
        "\n",
        "torch.manual_seed(42)\n",
        "for input,label in dataloader:\n",
        "  print(\"Input: \",input)\n",
        "  print(\"Label: \",label)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GUoF_-JNECm",
        "outputId": "850343f0-3612-4c0e-8203-a97d9befbb46"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  tensor([[ 134,    6,   93,    4,    0],\n",
            "        [ 386,   30,  139,  559,   12],\n",
            "        [   1,  161,   19, 1997,  249]])\n",
            "Label:  tensor([[   6,   93,    4,    0,   86],\n",
            "        [  30,  139,  559,   12,  174],\n",
            "        [ 161,   19, 1997,  249,    2]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition"
      ],
      "metadata": {
        "id": "rmwUqha5oAdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## likely to change\n",
        "vocab_size = len(Vocab)\n",
        "embed_dim = 128\n",
        "rnn_hidden_size = 64\n",
        "fc_hidden_size = 64"
      ],
      "metadata": {
        "id": "hBJ0xK4m6QvC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModelling(nn.Module):\n",
        "\n",
        "  def __init__(self,vocab_size,embed_dim,rnn_hidden_dim,fc_hidden_dim,):\n",
        "    super(LanguageModelling,self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "    self.lstm = nn.LSTM(embed_dim,rnn_hidden_dim,batch_first=True)\n",
        "    self.fc = nn.Linear(rnn_hidden_dim,fc_hidden_dim)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self,input):\n",
        "    ## initial hidden state and cell state default to zero vector\n",
        "    out = self.embedding(input)\n",
        "    out,(hidden,cell) = self.lstm(out)\n",
        "    out = self.fc(out)\n",
        "    out = self.softmax(out)\n",
        "    return out, hidden, cell"
      ],
      "metadata": {
        "id": "gUXheAQVo0nA"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training and Evaluation"
      ],
      "metadata": {
        "id": "CX6yeHEtZ6LH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModelling(vocab_size,embed_dim,rnn_hidden_size,fc_hidden_size)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIT6ZdFMa1rl",
        "outputId": "c0b4a257-4d74-411c-e634-b2722b066c71"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModelling(\n",
              "  (embedding): Embedding(2618, 128)\n",
              "  (lstm): LSTM(128, 64, batch_first=True)\n",
              "  (fc): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001) "
      ],
      "metadata": {
        "id": "sfyo6FGhZuq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data_iter):\n",
        "  pass"
      ],
      "metadata": {
        "id": "a3iZ3muRbZpT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}